{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load helpers.py\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, DecisionTreeClassifier, GBTClassifier, \\\n",
    "    RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
    "from pyspark.sql.functions import current_date, expr, datediff, to_date\n",
    "from pyspark.sql.functions import length, regexp_replace\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def get_kv_pairs(row, exclusions=[]):\n",
    "    # get the text from the row entry\n",
    "    text = str(row.review_body).lower()\n",
    "    # create blacklist of words\n",
    "    blacklist = set(stopwords.words('english'))\n",
    "    # add explicit words\n",
    "    [blacklist.add(i) for i in exclusions]\n",
    "    # extract all words\n",
    "    words = re.findall(r'([^\\w+])', text)\n",
    "    # for each word, send back a count of 1\n",
    "    # send a list of lists\n",
    "    return [[w, 1] for w in words if w not in blacklist]\n",
    "\n",
    "\n",
    "def get_word_counts(texts, exclusions=[]):\n",
    "    mapped_rdd = texts.rdd.flatMap(lambda row: get_kv_pairs(row, exclusions))\n",
    "    counts_rdd = mapped_rdd.reduceByKey(lambda a, b: a + b).sortByKey(True, 1)\n",
    "    return counts_rdd.collect()\n",
    "\n",
    "\n",
    "def convert_str_to_int(df, col='verified_purchase', type_='int'):\n",
    "    return df.select((df[col] == 'Y').cast(type_))\n",
    "\n",
    "\n",
    "def get_review_age(df):\n",
    "    return df.select(datediff(current_date(), to_date(df['review_date'])))\n",
    "\n",
    "\n",
    "def prepare_features(df):\n",
    "    df = df.withColumn('exclam', length('review_body') - length(regexp_replace('review_body', '\\!', '')))\n",
    "    df = df.withColumn('age', datediff(current_date(), to_date(df['review_date'])))\n",
    "    df = df.withColumn('review_length', length(df['review_body']))\n",
    "    df = df.withColumn('helfulness', df['helpful_votes'] / df['total_votes'])\n",
    "    df = df.withColumn('label', expr(\"CAST(verified_purchase='Y' As INT)\"))\n",
    "    select_cols = df.select(['star_rating', 'helfulness', 'age', 'review_length', 'label']).na.fill(0)\n",
    "    return select_cols\n",
    "\n",
    "\n",
    "def split_data(df, rate=.9):\n",
    "    training = df.sampleBy(\"label\", fractions={0: rate, 1: rate}, seed=12)\n",
    "    return training, df.subtract(training)\n",
    "\n",
    "\n",
    "def get_auc_roc(classifier, training, test):\n",
    "    model = classifier.fit(training)\n",
    "    out = model.transform(test) \\\n",
    "        .select(\"prediction\", \"label\") \\\n",
    "        .rdd.map(lambda x: (float(x[0]), float(x[1])))\n",
    "    metrics = MulticlassMetrics(out)\n",
    "#     print(\"Model: {1}. Area under ROC: {0:2f}\".format(metrics.areaUnderROC, clf.__class__))\n",
    "    return model, out, metrics\n",
    "\n",
    "\n",
    "def get_vectorized_features(df, cols=['star_rating']):\n",
    "    va = VectorAssembler().setInputCols(cols).setOutputCol(\n",
    "        'features')\n",
    "    return va.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load environment.py\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, DecisionTreeClassifier, GBTClassifier, \\\n",
    "    RandomForestClassifier\n",
    "import pyspark as ps\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType\n",
    "\n",
    "DATA_FILE = '../../amazon_reviews_us_Camera_v1_00.tsv.gz'\n",
    "APP_NAME = 'Prediction'\n",
    "FEATURES = ['star_rating', 'review_body', 'helpful_votes', 'total_votes', 'verified_purchase', 'review_date']\n",
    "SAMPLE_SIZE = 10000\n",
    "\n",
    "review_schema = StructType(\n",
    "    [StructField('marketplace', StringType(), True),\n",
    "     StructField('customer_id', StringType(), True),\n",
    "     StructField('review_id', StringType(), True),\n",
    "     StructField('product_id', StringType(), True),\n",
    "     StructField('product_parent', StringType(), True),\n",
    "     StructField('product_title', StringType(), True),\n",
    "     StructField('product_category', StringType(), True),\n",
    "     StructField('star_rating', IntegerType(), True),\n",
    "     StructField('helpful_votes', IntegerType(), True),\n",
    "     StructField('total_votes', IntegerType(), True),\n",
    "     StructField('vine', StringType(), True),\n",
    "     StructField('verified_purchase', StringType(), True),\n",
    "     StructField('review_headline', StringType(), True),\n",
    "     StructField('review_body', StringType(), True),\n",
    "     StructField('review_date', StringType(), True)])\n",
    "\n",
    "spark = (ps.sql.SparkSession.builder\n",
    "         .master(\"local[1]\")\n",
    "         .appName(APP_NAME)\n",
    "         .getOrCreate()\n",
    "         )\n",
    "sc = spark.sparkContext\n",
    "\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .schema(review_schema) \\\n",
    "    .load(DATA_FILE)\n",
    "\n",
    "review_all = df.select(FEATURES)\n",
    "review_sample = df.select(FEATURES).limit(SAMPLE_SIZE).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(), NaiveBayes(), DecisionTreeClassifier(), RandomForestClassifier(),\n",
    "                   GBTClassifier()]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10000 sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|  739|\n",
      "|    1|  731|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "select_cols = prepare_features(review_sample)\n",
    "features = get_vectorized_features(select_cols, cols=['star_rating', 'helfulness', 'age', 'review_length'])\n",
    "training = features.sampleBy(\"label\", fractions={0: 0.92, 1: 0.08}, seed=12)\n",
    "training.groupBy(\"label\").count().orderBy(\"label\").show()\n",
    "test = features.subtract(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classifiers:\n",
    "    model, out, metrics = get_auc_roc(clf, training, test)\n",
    "    results.append([model, out, metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted recall = 0.689262147570486\n",
      "Weighted precision = 0.9792100730429228\n",
      "Weighted F(1) Score = 0.8034419158790111\n",
      "Weighted F(0.5) Score = 0.9003234429759306\n",
      "Weighted false positive rate = 0.3564840961755211\n",
      "Weighted recall = 0.7790441911617676\n",
      "Weighted precision = 0.9791545542977921\n",
      "Weighted F(1) Score = 0.8633698529601728\n",
      "Weighted F(0.5) Score = 0.9292102146390998\n",
      "Weighted false positive rate = 0.4115412216105321\n",
      "Weighted recall = 0.5708858228354329\n",
      "Weighted precision = 0.9803966893858123\n",
      "Weighted F(1) Score = 0.7136342816579638\n",
      "Weighted F(0.5) Score = 0.8527631351071943\n",
      "Weighted false positive rate = 0.24550122973638028\n",
      "Weighted recall = 0.5390921815636872\n",
      "Weighted precision = 0.9807625520840806\n",
      "Weighted F(1) Score = 0.6870836834289293\n",
      "Weighted F(0.5) Score = 0.8374479538179295\n",
      "Weighted false positive rate = 0.21778673786927583\n",
      "Weighted recall = 0.5520895820835833\n",
      "Weighted precision = 0.9805409767026941\n",
      "Weighted F(1) Score = 0.6980855737531481\n",
      "Weighted F(0.5) Score = 0.8438387487631391\n",
      "Weighted false positive rate = 0.23168514369090717\n"
     ]
    }
   ],
   "source": [
    "for m,o,metrics in results[-5:]:\n",
    "    print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "    print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "    print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "    print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "    print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,o,metrics = results[1]\n",
    "ys=list(zip(*o.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:85: DeprecationWarning: Function plot_roc_curve is deprecated; This will be removed in v0.5.0. Please use scikitplot.metrics.plot_roc instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-6163e748da1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# ground truth labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# predicted probabilities generated by sklearn classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mskplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_probas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scikitplot/metrics.py\u001b[0m in \u001b[0;36mplot_roc_curve\u001b[0;34m(y_true, y_probas, title, curves, ax, figsize, cmap, title_fontsize, text_fontsize)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         fpr[i], tpr[i], _ = roc_curve(y_true, probas[:, i],\n\u001b[0m\u001b[1;32m    258\u001b[0m                                       pos_label=classes[i])\n\u001b[1;32m    259\u001b[0m         \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = ys[0]# ground truth labels\n",
    "y_probas = ys[1]# predicted probabilities generated by sklearn classifier\n",
    "skplt.metrics.plot_roc_curve(y_true, y_probas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = prepare_features(review_all)\n",
    "features = get_vectorized_features(select_cols, cols=['star_rating', 'helfulness', 'age', 'review_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|    0| 307573|\n",
      "|    1|1494401|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features.groupBy(\"label\").count().orderBy(\"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    0|246383|\n",
      "|    1|246651|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training = features.sampleBy(\"label\", fractions={0: 0.80, 1: 0.165}, seed=24)\n",
    "training.groupBy(\"label\").count().orderBy(\"label\").show()\n",
    "test = features.subtract(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'pyspark.ml.classification.LogisticRegression'>. Area under ROC: 0.683608\n",
      "Model: <class 'pyspark.ml.classification.NaiveBayes'>. Area under ROC: 0.555252\n",
      "Model: <class 'pyspark.ml.classification.DecisionTreeClassifier'>. Area under ROC: 0.704910\n",
      "Model: <class 'pyspark.ml.classification.RandomForestClassifier'>. Area under ROC: 0.700429\n",
      "Model: <class 'pyspark.ml.classification.GBTClassifier'>. Area under ROC: 0.710810\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    model, out, metrics = get_auc_roc(clf, training, test)\n",
    "    results.append([model, out, metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marketplace',\n",
       " 'customer_id',\n",
       " 'review_id',\n",
       " 'product_id',\n",
       " 'product_parent',\n",
       " 'product_title',\n",
       " 'product_category',\n",
       " 'star_rating',\n",
       " 'helpful_votes',\n",
       " 'total_votes',\n",
       " 'vine',\n",
       " 'verified_purchase',\n",
       " 'review_headline',\n",
       " 'review_body',\n",
       " 'review_date']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
